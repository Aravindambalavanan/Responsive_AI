{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyORf6VRVyG6xadaeO73lhp3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":13,"metadata":{"id":"A0ru4S35FKtv","executionInfo":{"status":"ok","timestamp":1702239026409,"user_tz":-330,"elapsed":14,"user":{"displayName":"Manigandan R","userId":"15242602112462302615"}}},"outputs":[],"source":["!pip install --upgrade profanity-check\n","!pip install youtube-transcript-api\n","!pip install scikit-learn\n","!pip install nltk\n","!pip install joblib\n","!pip install alt-profanity-check\n","!pip install sklearn --upgrade\n","!pip install streamlit\n","!pip install streamlit pyngrok"]},{"cell_type":"code","source":["%%writefile app.py\n","import streamlit as st\n","import warnings\n","from matplotlib.cbook import MatplotlibDeprecationWarning\n","from youtube_transcript_api import YouTubeTranscriptApi\n","from nltk.sentiment import SentimentIntensityAnalyzer\n","import nltk\n","import matplotlib.pyplot as plt\n","from wordcloud import WordCloud\n","from googleapiclient.discovery import build\n","from profanity_check import predict_prob\n","\n","# Ignore Streamlit warnings and errors\n","st.set_option('deprecation.showPyplotGlobalUse', False)\n","warnings.filterwarnings(\"ignore\", category=MatplotlibDeprecationWarning)\n","\n","# Download NLTK data (if not already downloaded)\n","nltk.download('vader_lexicon')\n","\n","# Set up YouTube API client with your API key\n","API_KEY = \"API_KEY\"  # Replace with your actual API key\n","youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n","\n","# Function to fetch the video transcript using the YouTube API\n","def generate_transcript(video_id, language='en'):\n","    transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=[language])\n","    script = \"\"\n","\n","    for text in transcript:\n","        t = text[\"text\"]\n","        if t != '[Music]':\n","            script += t + \" \"\n","\n","    return script\n","\n","# Function to analyze sentiment in text using the NLTK library\n","def analyze_sentiment(text):\n","    analyzer = SentimentIntensityAnalyzer()\n","    sentiment_scores = analyzer.polarity_scores(text)\n","    compound_score = sentiment_scores['compound']\n","\n","    # Assign a sentiment label based on the compound score\n","    if compound_score >= 0.05:\n","        return 'positive'\n","    elif compound_score <= -0.05:\n","        return 'negative'\n","    else:\n","        return 'neutral'\n","\n","# Function to plot a pie chart for sentiment distribution\n","def plot_pie_chart(labels, sizes, title):\n","    fig, ax = plt.subplots()\n","    ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n","    ax.set_title(title)\n","    return fig  # Return the figure for Streamlit to display\n","\n","# Function to count sentiment words in text\n","def count_sentiment_words(text):\n","    analyzer = SentimentIntensityAnalyzer()\n","    sentiment_words = {'positive': 0, 'neutral': 0, 'negative': 0}\n","\n","    for word in text.split():\n","        sentiment = analyze_sentiment(word + ' ')\n","        sentiment_words[sentiment] += 1\n","\n","    return sentiment_words\n","\n","# Function to plot a bar chart for sentiment word counts\n","def plot_bar_chart(data, title, xlabel, ylabel):\n","    fig, ax = plt.subplots()\n","    labels = list(data.keys())\n","    values = list(data.values())\n","    ax.bar(labels, values, color=['green', 'yellow', 'red'])\n","    ax.set_title(title)\n","    ax.set_xlabel(xlabel)\n","    ax.set_ylabel(ylabel)\n","    return fig  # Return the figure for Streamlit to display\n","\n","# Function to analyze explicit content using the profanity_check library\n","def analyze_explicit_content(text):\n","    explicit_score = predict_prob([text])\n","    return explicit_score[0]\n","\n","# Function to classify explicit content based on a threshold\n","def classify_explicit_content(explicit_score, threshold=0.5):\n","    if explicit_score >= threshold:\n","        return 'explicit'\n","    else:\n","        return 'non-explicit'\n","\n","# Function to generate word cloud from text\n","def generate_word_cloud(text):\n","    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n","    plt.figure(figsize=(10, 5))\n","    plt.imshow(wordcloud, interpolation='bilinear')\n","    plt.axis('off')\n","    st.pyplot()\n","\n","# Function to analyze and plot various aspects of a YouTube video\n","def analyze_and_plot(video_url, language):\n","    # Extract video ID from the YouTube link\n","    video_id = video_url.split(\"v=\")[1]\n","\n","    transcript = generate_transcript(video_id, language)\n","\n","    # Analyze sentiment for the main video\n","    sentiments = {'positive': 0, 'neutral': 0, 'negative': 0}\n","    negative_words_count = 0\n","\n","    # Analyze explicit content for the main video\n","    explicit_content_score = analyze_explicit_content(transcript)\n","\n","    # Classify explicit content\n","    explicit_class = classify_explicit_content(explicit_content_score)\n","\n","    # Loop through each sentence in the transcript\n","    for sentence in transcript.split('.'):\n","        sentiment = analyze_sentiment(sentence)\n","        sentiments[sentiment] += 1\n","\n","        # Count negative words\n","        if sentiment == 'negative':\n","            negative_words_count += len(sentence.split())\n","\n","    # Display results\n","    st.header(\"YouTube Video Classification Results\")\n","    st.subheader(f\"Results for Video: {video_id}\")\n","\n","    # Classification Tab\n","    st.write(\"## Classification\")\n","\n","    # Sentiment Analysis\n","    st.subheader(\"Sentiment Analysis:\")\n","    st.write(sentiments)\n","    # Plot pie chart for sentiment distribution of the main video\n","    fig_pie = plot_pie_chart(sentiments.keys(), sentiments.values(), f'Sentiment Distribution - {video_id}')\n","    st.pyplot(fig_pie)\n","\n","    # Sentiment Word Counts\n","    st.subheader(\"Sentiment Word Counts:\")\n","    sentiment_words_count = count_sentiment_words(transcript)\n","    st.write(sentiment_words_count)\n","    # Plot bar chart for sentiment word counts of the main video\n","    fig_bar = plot_bar_chart(sentiment_words_count, f'Sentiment Word Counts - {video_id}', 'Sentiment', 'Word Count')\n","    st.pyplot(fig_bar)\n","\n","    # Total Number of Negative Words\n","    st.subheader(f\"Total Number of Negative Words - {video_id}\")\n","    st.write(negative_words_count)\n","\n","    # Explicit Content Analysis\n","    st.subheader(f\"Explicit Content Analysis - {video_id}\")\n","    st.write(f\"Explicit Content Score: {explicit_content_score}\")\n","    st.write(f\"Explicit Content Class: {explicit_class}\")\n","\n","    # Word Cloud\n","    st.subheader(f\"Word Cloud - {video_id}\")\n","    generate_word_cloud(transcript)\n","\n","    # About Tab\n","    st.write(\"## About\")\n","    # Display details of the main video\n","    st.subheader(f\"Details for Main Video - {video_id}\")\n","    st.write(f\"Video ID: {video_id}\")\n","    video_info = youtube.videos().list(part='snippet', id=video_id).execute()\n","    st.write(f\"Title: {video_info['items'][0]['snippet']['title']}\")\n","    st.write(f\"Description: {video_info['items'][0]['snippet']['description']}\")\n","    st.write(f\"Thumbnail URL: {video_info['items'][0]['snippet']['thumbnails']['default']['url']}\")\n","    st.write(f\"Subtitles: {transcript}\")\n","\n","# Streamlit App\n","def main():\n","    st.title(\"YouTube Video Classification App\")\n","\n","    # Add tabs\n","    tabs = [\"Home\", \"Classification\", \"About\"]\n","    selected_tab = st.sidebar.selectbox(\"Select Tab\", tabs)\n","\n","    if selected_tab == \"Home\":\n","        st.write(\"## Welcome to the YouTube Video Classification App!\")\n","        st.write(\"This app classify YouTube videos based on sentiment and explicit content.\")\n","        st.write(\"## YouTube's Community Guidelines \")\n","        st.write(\"Violent or dangerous content: Hate speech, predatory behavior, graphic violence, malicious attacks, and content that promotes harmful or dangerous behavior isn't allowed on YouTube.\")\n","        st.write(\"Words that are often flagged in content moderation are \")\n","        st.write(\"1. Profanity: Common swear words and offensive language.\")\n","        st.write(\"2. Hate Speech: Words or phrases that promote discrimination, violence, or hatred towards individuals or groups based on attributes such as race, ethnicity, religion, gender, etc.\")\n","        st.write(\"3. Harassment: Words that are used to harass or threaten others.\")\n","        st.write(\"4. Violence: Terms related to violent actions or harm.\")\n","        st.write(\"5. Explicit Content: Words related to explicit or adult content.\")\n","        st.write(\" \")\n","    elif selected_tab == \"Classification\":\n","        # User input for YouTube video URL\n","        video_url = st.text_input(\"Enter YouTube Video URL:\")\n","        if not video_url:\n","            st.warning(\"Please enter a YouTube Video URL.\")\n","            st.stop()\n","\n","        # User input for subtitles language\n","        language = st.selectbox(\"Select Subtitles Language:\", [\"en\", \"es\", \"fr\", \"de\",\"ta\",\"hi\"])  # Add more language options if needed\n","\n","        # Button to classify the video\n","        if st.button(\"Classify Video\"):\n","            # Analyze and plot aspects of the YouTube video\n","            analyze_and_plot(video_url, language)\n","    elif selected_tab == \"About\":\n","        st.write(\"## About the App\")\n","        st.write(\"This app uses natural language processing techniques to analyze and classify YouTube videos based on sentiment and explicit content.\")\n","        st.write(\"Built with Streamlit, NLTK, Matplotlib, YouTube API, and Profanity Check.\")\n","        st.write(\"Team Members: Manigandan, Sai Kiran, Sarinika\")\n","        st.write(\"Guide: Mr. Muthumani, Dr. M. Deivamani\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"13C-KqWLQZrg","executionInfo":{"status":"ok","timestamp":1702239035694,"user_tz":-330,"elapsed":379,"user":{"displayName":"Manigandan R","userId":"15242602112462302615"}},"outputId":"c5e0f9b7-328c-4f80-d08f-e438d909d90a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}]},{"cell_type":"code","source":["!streamlit run app.py & npx localtunnel --port 8501"],"metadata":{"id":"fbd4KHniQtma","executionInfo":{"status":"ok","timestamp":1702239448674,"user_tz":-330,"elapsed":383,"user":{"displayName":"Manigandan R","userId":"15242602112462302615"}}},"execution_count":16,"outputs":[]}]}