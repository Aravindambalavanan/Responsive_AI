{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyORf6VRVyG6xadaeO73lhp3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A0ru4S35FKtv","executionInfo":{"status":"ok","timestamp":1702235651154,"user_tz":-330,"elapsed":71019,"user":{"displayName":"Manigandan R","userId":"15242602112462302615"}},"outputId":"b99ab9df-3952-45dc-f21a-9114133da635"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting profanity-check\n","  Downloading profanity_check-1.0.3-py3-none-any.whl (2.4 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/2.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/2.4 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from profanity-check) (1.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.2->profanity-check) (1.23.5)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.2->profanity-check) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.2->profanity-check) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.2->profanity-check) (3.2.0)\n","Installing collected packages: profanity-check\n","Successfully installed profanity-check-1.0.3\n","Collecting youtube-transcript-api\n","  Downloading youtube_transcript_api-0.6.1-py3-none-any.whl (24 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2023.11.17)\n","Installing collected packages: youtube-transcript-api\n","Successfully installed youtube-transcript-api-0.6.1\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.3.2)\n","Collecting alt-profanity-check\n","  Downloading alt-profanity-check-1.3.2.tar.gz (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting scikit-learn==1.3.2 (from alt-profanity-check)\n","  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: joblib>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from alt-profanity-check) (1.3.2)\n","Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.2->alt-profanity-check) (1.23.5)\n","Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.2->alt-profanity-check) (1.11.4)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.2->alt-profanity-check) (3.2.0)\n","Building wheels for collected packages: alt-profanity-check\n","  Building wheel for alt-profanity-check (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for alt-profanity-check: filename=alt_profanity_check-1.3.2-py3-none-any.whl size=1866996 sha256=debe5b3670ae29e185b352e7bf9ad0071e514a5a3cdaaa2bffb4119320e20505\n","  Stored in directory: /root/.cache/pip/wheels/b3/b9/e1/e1ace2573792813935cd59a2f8a0cecc807bd2dbf69327a0b3\n","Successfully built alt-profanity-check\n","Installing collected packages: scikit-learn, alt-profanity-check\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","Successfully installed alt-profanity-check-1.3.2 scikit-learn-1.3.2\n","Collecting sklearn\n","  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n","\n","\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n","\u001b[1;36mhint\u001b[0m: See above for details.\n","Collecting streamlit\n","  Downloading streamlit-1.29.0-py2.py3-none-any.whl (8.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n","Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n","Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n","Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.8.0)\n","Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.23.5)\n","Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n","Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n","Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n","Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n","Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n","Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n","Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.0)\n","Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.5.0)\n","Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.2)\n","Collecting validators<1,>=0.2 (from streamlit)\n","  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n","Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n","  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n","  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n","Collecting watchdog>=2.1.5 (from streamlit)\n","  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n","Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit) (3.17.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2023.11.17)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.11.2)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.31.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.13.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n","Installing collected packages: watchdog, validators, smmap, pydeck, gitdb, gitpython, streamlit\n","Successfully installed gitdb-4.0.11 gitpython-3.1.40 pydeck-0.8.1b0 smmap-5.0.1 streamlit-1.29.0 validators-0.22.0 watchdog-3.0.0\n","Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.29.0)\n","Collecting pyngrok\n","  Downloading pyngrok-7.0.3-py3-none-any.whl (21 kB)\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n","Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n","Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n","Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.8.0)\n","Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.23.5)\n","Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n","Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n","Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n","Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n","Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n","Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n","Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.0)\n","Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.5.0)\n","Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.2)\n","Requirement already satisfied: validators<1,>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.22.0)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.40)\n","Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.8.1b0)\n","Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n","Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.0.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit) (3.17.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2023.11.17)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.11.2)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.31.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.13.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n","Installing collected packages: pyngrok\n","Successfully installed pyngrok-7.0.3\n"]}],"source":["!pip install --upgrade profanity-check\n","!pip install youtube-transcript-api\n","!pip install scikit-learn\n","!pip install nltk\n","!pip install joblib\n","!pip install alt-profanity-check\n","!pip install sklearn --upgrade\n","!pip install streamlit\n","!pip install streamlit pyngrok"]},{"cell_type":"code","source":["%%writefile app.py\n","import streamlit as st\n","import warnings\n","from matplotlib.cbook import MatplotlibDeprecationWarning\n","from youtube_transcript_api import YouTubeTranscriptApi\n","from nltk.sentiment import SentimentIntensityAnalyzer\n","import nltk\n","import matplotlib.pyplot as plt\n","from wordcloud import WordCloud\n","from googleapiclient.discovery import build\n","from profanity_check import predict_prob\n","\n","# Ignore Streamlit warnings and errors\n","st.set_option('deprecation.showPyplotGlobalUse', False)\n","warnings.filterwarnings(\"ignore\", category=MatplotlibDeprecationWarning)\n","\n","# Download NLTK data (if not already downloaded)\n","nltk.download('vader_lexicon')\n","\n","# Set up YouTube API client with your API key\n","API_KEY = \"API_KEY\"  # Replace with your actual API key\n","youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n","\n","# Function to fetch the video transcript using the YouTube API\n","def generate_transcript(video_id, language='en'):\n","    transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=[language])\n","    script = \"\"\n","\n","    for text in transcript:\n","        t = text[\"text\"]\n","        if t != '[Music]':\n","            script += t + \" \"\n","\n","    return script\n","\n","# Function to analyze sentiment in text using the NLTK library\n","def analyze_sentiment(text):\n","    analyzer = SentimentIntensityAnalyzer()\n","    sentiment_scores = analyzer.polarity_scores(text)\n","    compound_score = sentiment_scores['compound']\n","\n","    # Assign a sentiment label based on the compound score\n","    if compound_score >= 0.05:\n","        return 'positive'\n","    elif compound_score <= -0.05:\n","        return 'negative'\n","    else:\n","        return 'neutral'\n","\n","# Function to plot a pie chart for sentiment distribution\n","def plot_pie_chart(labels, sizes, title):\n","    fig, ax = plt.subplots()\n","    ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n","    ax.set_title(title)\n","    return fig  # Return the figure for Streamlit to display\n","\n","# Function to count sentiment words in text\n","def count_sentiment_words(text):\n","    analyzer = SentimentIntensityAnalyzer()\n","    sentiment_words = {'positive': 0, 'neutral': 0, 'negative': 0}\n","\n","    for word in text.split():\n","        sentiment = analyze_sentiment(word + ' ')\n","        sentiment_words[sentiment] += 1\n","\n","    return sentiment_words\n","\n","# Function to plot a bar chart for sentiment word counts\n","def plot_bar_chart(data, title, xlabel, ylabel):\n","    fig, ax = plt.subplots()\n","    labels = list(data.keys())\n","    values = list(data.values())\n","    ax.bar(labels, values, color=['green', 'yellow', 'red'])\n","    ax.set_title(title)\n","    ax.set_xlabel(xlabel)\n","    ax.set_ylabel(ylabel)\n","    return fig  # Return the figure for Streamlit to display\n","\n","# Function to analyze explicit content using the profanity_check library\n","def analyze_explicit_content(text):\n","    explicit_score = predict_prob([text])\n","    return explicit_score[0]\n","\n","# Function to classify explicit content based on a threshold\n","def classify_explicit_content(explicit_score, threshold=0.5):\n","    if explicit_score >= threshold:\n","        return 'explicit'\n","    else:\n","        return 'non-explicit'\n","\n","# Function to generate word cloud from text\n","def generate_word_cloud(text):\n","    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n","    plt.figure(figsize=(10, 5))\n","    plt.imshow(wordcloud, interpolation='bilinear')\n","    plt.axis('off')\n","    st.pyplot()\n","\n","# Function to analyze and plot various aspects of a YouTube video\n","def analyze_and_plot(video_url, language):\n","    # Extract video ID from the YouTube link\n","    video_id = video_url.split(\"v=\")[1]\n","\n","    transcript = generate_transcript(video_id, language)\n","\n","    # Analyze sentiment for the main video\n","    sentiments = {'positive': 0, 'neutral': 0, 'negative': 0}\n","    negative_words_count = 0\n","\n","    # Analyze explicit content for the main video\n","    explicit_content_score = analyze_explicit_content(transcript)\n","\n","    # Classify explicit content\n","    explicit_class = classify_explicit_content(explicit_content_score)\n","\n","    # Loop through each sentence in the transcript\n","    for sentence in transcript.split('.'):\n","        sentiment = analyze_sentiment(sentence)\n","        sentiments[sentiment] += 1\n","\n","        # Count negative words\n","        if sentiment == 'negative':\n","            negative_words_count += len(sentence.split())\n","\n","    # Display results\n","    st.header(\"YouTube Video Classification Results\")\n","    st.subheader(f\"Results for Video: {video_id}\")\n","\n","    # Classification Tab\n","    st.write(\"## Classification\")\n","\n","    # Sentiment Analysis\n","    st.subheader(\"Sentiment Analysis:\")\n","    st.write(sentiments)\n","    # Plot pie chart for sentiment distribution of the main video\n","    fig_pie = plot_pie_chart(sentiments.keys(), sentiments.values(), f'Sentiment Distribution - {video_id}')\n","    st.pyplot(fig_pie)\n","\n","    # Sentiment Word Counts\n","    st.subheader(\"Sentiment Word Counts:\")\n","    sentiment_words_count = count_sentiment_words(transcript)\n","    st.write(sentiment_words_count)\n","    # Plot bar chart for sentiment word counts of the main video\n","    fig_bar = plot_bar_chart(sentiment_words_count, f'Sentiment Word Counts - {video_id}', 'Sentiment', 'Word Count')\n","    st.pyplot(fig_bar)\n","\n","    # Total Number of Negative Words\n","    st.subheader(f\"Total Number of Negative Words - {video_id}\")\n","    st.write(negative_words_count)\n","\n","    # Explicit Content Analysis\n","    st.subheader(f\"Explicit Content Analysis - {video_id}\")\n","    st.write(f\"Explicit Content Score: {explicit_content_score}\")\n","    st.write(f\"Explicit Content Class: {explicit_class}\")\n","\n","    # Word Cloud\n","    st.subheader(f\"Word Cloud - {video_id}\")\n","    generate_word_cloud(transcript)\n","\n","    # About Tab\n","    st.write(\"## About\")\n","    # Display details of the main video\n","    st.subheader(f\"Details for Main Video - {video_id}\")\n","    st.write(f\"Video ID: {video_id}\")\n","    video_info = youtube.videos().list(part='snippet', id=video_id).execute()\n","    st.write(f\"Title: {video_info['items'][0]['snippet']['title']}\")\n","    st.write(f\"Description: {video_info['items'][0]['snippet']['description']}\")\n","    st.write(f\"Thumbnail URL: {video_info['items'][0]['snippet']['thumbnails']['default']['url']}\")\n","    st.write(f\"Subtitles: {transcript}\")\n","\n","# Streamlit App\n","def main():\n","    st.title(\"YouTube Video Classification App\")\n","\n","    # Add tabs\n","    tabs = [\"Home\", \"Classification\", \"About\"]\n","    selected_tab = st.sidebar.selectbox(\"Select Tab\", tabs)\n","\n","    if selected_tab == \"Home\":\n","        st.write(\"## Welcome to the YouTube Video Classification App!\")\n","        st.write(\"This app classify YouTube videos based on sentiment and explicit content.\")\n","        st.write(\"## YouTube's Community Guidelines \")\n","        st.write(\"Violent or dangerous content: Hate speech, predatory behavior, graphic violence, malicious attacks, and content that promotes harmful or dangerous behavior isn't allowed on YouTube.\")\n","        st.write(\"Words that are often flagged in content moderation are \")\n","        st.write(\"1. Profanity: Common swear words and offensive language.\")\n","        st.write(\"2. Hate Speech: Words or phrases that promote discrimination, violence, or hatred towards individuals or groups based on attributes such as race, ethnicity, religion, gender, etc.\")\n","        st.write(\"3. Harassment: Words that are used to harass or threaten others.\")\n","        st.write(\"4. Violence: Terms related to violent actions or harm.\")\n","        st.write(\"5. Explicit Content: Words related to explicit or adult content.\")\n","        st.write(\" \")\n","    elif selected_tab == \"Classification\":\n","        # User input for YouTube video URL\n","        video_url = st.text_input(\"Enter YouTube Video URL:\")\n","        if not video_url:\n","            st.warning(\"Please enter a YouTube Video URL.\")\n","            st.stop()\n","\n","        # User input for subtitles language\n","        language = st.selectbox(\"Select Subtitles Language:\", [\"en\", \"es\", \"fr\", \"de\",\"ta\",\"hi\"])  # Add more language options if needed\n","\n","        # Button to classify the video\n","        if st.button(\"Classify Video\"):\n","            # Analyze and plot aspects of the YouTube video\n","            analyze_and_plot(video_url, language)\n","    elif selected_tab == \"About\":\n","        st.write(\"## About the App\")\n","        st.write(\"This app uses natural language processing techniques to analyze and classify YouTube videos based on sentiment and explicit content.\")\n","        st.write(\"Built with Streamlit, NLTK, Matplotlib, YouTube API, and Profanity Check.\")\n","        st.write(\"Team Members: Manigandan, Sai Kiran, Sarinika\")\n","        st.write(\"Guide: Mr. Muthumani, Dr. M. Deivamani\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"13C-KqWLQZrg","executionInfo":{"status":"ok","timestamp":1702237871893,"user_tz":-330,"elapsed":16,"user":{"displayName":"Manigandan R","userId":"15242602112462302615"}},"outputId":"2cc23af9-463e-4f07-c240-5e3038f17c51"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}]},{"cell_type":"code","source":["!streamlit run app.py & npx localtunnel --port 8501"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fbd4KHniQtma","executionInfo":{"status":"ok","timestamp":1702237844828,"user_tz":-330,"elapsed":61260,"user":{"displayName":"Manigandan R","userId":"15242602112462302615"}},"outputId":"67af11d7-e039-4ac0-bd51-0d82460d50e4"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l[..................] / rollbackFailedOptional: verb npm-session 501717852415eb4\u001b[0m\u001b[K\r[..................] \\ fetchMetadata: sill resolveWithNewModule localtunnel@2.0\u001b[0m\u001b[K\r[..................] \\ fetchMetadata: sill resolveWithNewModule localtunnel@2.0\u001b[0m\u001b[K\r[#.................] - fetchMetadata: sill resolveWithNewModule follow-redirect\u001b[0m\u001b[K\r[#.................] - fetchMetadata: sill resolveWithNewModule follow-redirect\u001b[0m\u001b[K\r\n","Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n","\u001b[0m\n","\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.237.61.233:8501\u001b[0m\n","\u001b[0m\n","\u001b[K\u001b[?25hnpx: installed 22 in 2.272s\n","your url is: https://shaky-banks-attack.loca.lt\n","/content/app.py:3: MatplotlibDeprecationWarning: MatplotlibDeprecationWarning was deprecated in Matplotlib 3.6 and will be removed two minor releases later. Use matplotlib.MatplotlibDeprecationWarning instead.\n","  from matplotlib.cbook import MatplotlibDeprecationWarning\n","[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data]   Package vader_lexicon is already up-to-date!\n","[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data]   Package vader_lexicon is already up-to-date!\n","[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data]   Package vader_lexicon is already up-to-date!\n","\u001b[34m  Stopping...\u001b[0m\n","^C\n"]}]}]}